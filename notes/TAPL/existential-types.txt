Exsitential Types
=================

Existential types are fundamentally no more complicated than universal types (in fact, we will see that existentials can straightforwardly be encoded in terms of universals). However, the introduction and elimination forms for existential types are syntactically a bit heavier than the simple type abstraction and application associated with universals, and some people find them slightly puzzling initially. The following intuitions may be helpful in getting through this phase.

The universal types can be viewed in two different ways. A logical intuition is that an element of the type "X.T is a value that has type [X |-> S]T for all choices of S. This intuition corresponds to a type-erasure view of behavior: for example, the polymorphic identity function λX.λx:X.x erases to the untyped identity function λx.x, which maps an argument from any type S to a result of the same type. By contrast, a more operational intuition is that an element of "X.T is a function mapping a type S to a specialized term with type [X |-> S]T. This intuition corresponds to our definition of System F where the reduction of a type application is considered an actual step of computation.

Similarly, there are two different ways of looking at an existential type, written {$X,T}. The logical intuition is that an element of {$X,T} is a value of type [X |-> S]T, for some type S. The operational intuition, on the other hand, is that an element of {$X,T} is a pair, written {*S,t}, of a type S and a term t of type [X |-> S]T.

We mark the type component of the pair with a * to avoid confusion with ordinary term-tuples. Another common notation for existential introduction is pack X=S with t.

We will emphasize the operational view of existential types in this chapter, because it provides a closer analogy between existentials and the modules and abstract data types found in programming languages. Our concrete syntax for existential types reflects this analogy: we write {$X,T} - the curly braces emphasizing that an existential value is a form of tuple-instead of the more standard notation $X.T.

To understand existential types, we need to know two things: how to build (or introduce, see Curry-Howard correspondence) elements that inhabit them, and how to use (or eliminate) these values in computations.

An existentially typed value is introduced by pairing a type with a term, written {*S,t}. A useful concrete intuition is to think of a value {*S,t} of type {$X,T} as a simple form of package or module with one (hidden) type component and one term component. The type S is often called the hidden representation type, or sometimes (to emphasize a connection with logic) the witness type of the package. For example, the package p = {*Nat, {a=5, f=λx:Nat. succ(x)}} has the existential type {$X, {a:X, f:X->X}}. The type component of p is Nat, and the value component is a record containing a field a of type X and a field f of type X->X, for some X (namely Nat).

Obviously, one could imagine generalizing these modules to many type and/or term components, but let's stick with just one of each to keep the notation tractable. The effect of multiple type components can be achieved by nesting single-type existentials, while the effect of multiple term components can be achieved by using a tuple or record as the right-hand component:

  {*S1, *S2, t1, t2} =def= {*S1, {*S2, {t1, t2}}}

The same package p also has the type {$X, {a:X, f:X->Nat}}, since its right-hand component is a record with fields a and f of type X and X->Nat, for some X (namely Nat). This example shows that, in general, the typechecker cannot make an automatic decision about which existential type a given package belongs to: the programmer must specify which one is intended. The simplest way to do this is just to add an annotation to every package that explicitly gives its intended type. So the full introduction form for existentials will look like this,

  p = {*Nat, {a=5, f=λx:Nat. succ(x)}} as {$X, {a:X, f:X->X}};
  > p : {$X, {a:X,f:X->X}}

  or (the same package with a different type):

  p1 = {*Nat, {a=5, f=λx:Nat. succ(x)}} as {$X, {a:X, f:X->Nat}};
  > p1 : {$X, {a:X,f:X->Nat}}

The typing rule for existential introduction is as follows:

  Г |- t2:[X |-> U]T2
  -----------------------------------    T-PACK
  Г |- {*U,t2} as {$X, T2} : {$X, T2}

One thing to notice about this rule is that packages with different hidden representation types can inhabit the same existential type. For example:

  p2 = {*Nat, 0} as {$X,X};
  > p2 : {$X, X}

  p3 = {*Bool, true} as {$X,X};
  > p3 : {$X, X}

Or, more usefully:

  p4 = {*Nat, {a=0, f=λx:Nat. succ(x)}} as {$X, {a:X, f:X->Nat}};
  > p4 : {$X, {a:X,f:X->Nat}}

  p5 = {*Bool, {a=true, f=λx:Bool. 0}} as {$X, {a:X, f:X->Nat}};
  > p5 : {$X, {a:X,f:X->Nat}}

The analogy with modules also offers a helpful intuition for the existential elimination construct. If an existential package corresponds to a module, then package elimination is like an open or import directive: it allows the components of the module to be used in some other part of the program, but holds abstract the identity of the module's type component. This can be achieved with a kind of pattern-matching binding:

  Г |- t1:{$X,T12}    Г,X,x:T12 |- t2:T2
  --------------------------------------    T-UNPACK
  Г |- let {X,x}=t1 in t2:T2

That is, if t1 is an expression that yields an existential package, then we can bind its type and term components to the pattern variables X and x and use them in computing t2. (Another common concrete syntax for existential elimination is open t1 as {X,x} in t2.)

For example, take the package p4, of type {$X, {a:X, f:X->Nat}}, defined above. The elimination expression

  let {X,x}=p4 in (x.f x.a);
  > 1 : Nat

opens p4 and uses the fields of its body (x.f and x.a) to compute a numeric result. The body of the elimination form can also involve the type variable X:

    let {X,x}=p4 in (λy:X. x.f y) x.a;
    > 1 : Nat

The fact that the package's representation type is held abstract during the typechecking of the body means that the only operations allowed on x are those warranted by its "abstract type" {a:X,f:X->Nat}. In particular, we are not allowed to use x.a concretely as a number:

  let {X,x}=p4 in succ(x.a);
  > Error: argument of succ is not a number

This restriction makes good sense, since we saw above that a package with the same existential type as p4 might use either Nat or Bool (or anything else) as its representation type.

There is another, more subtle, way in which typechecking of the existential elimination construct may fail. In the rule T-UNPACK, the type variable X appears in the context in which t2's type is calculated, but does not appear in the context of the rule's conclusion. This means that the result type T2 cannot contain X free, since any free occurrences of X will be out of scope in the conclusion.

  let {X,x}=p in x.a;
  > Error: Scoping error!

The computation rule for existentials is straightforward:

  let {X,x}=({*T11,v12} as T1) in t2 -> [X |->T11][x |-> v12]t2    (E-UNPACKPACK)

If the first subexpression of the let has already been reduced to a concrete package, then we may substitute the components of this package for the variables X and x in the body t2. In terms of the analogy with modules, this rule can be viewed as a linking step, in which symbolic names (X and x) referring to the components of a separately compiled module are replaced by the actual contents of the module.

Since the type variable X is substituted away by this rule, the resulting program actually has concrete access to the package's internals. This is just another example of a phenomenon we have seen several times: expressions can become "more typed" as computation proceeds - in particular an ill-typed expression can reduce to a well-typed one.

The rules defining the extension of System F with existential types are summarized below:

Existential types (Extended System F)
---------------------------------------------------------
t ::=                             terms
      {*T,t} as T                 packing
      let (X,x)=t in t            unpacking

v ::=                             values
      {*T,v} as T                 package value

T ::=                             types
      {$X,T}                      exsitential type

Evaluation                        t->t'

let (X,x)=({*T11,v12} as T1) in t2
-> [X |-> T11][x |-> v12]t2       E-UNPACKPACK

t12 -> t12'
-------------------------------------    E-PACK
{*T11,t12} as T1 -> {*T11,t12'} as T1

t1 -> t1'
-----------------------------------------    E-UNPACK
let {X,x}=t1 in t2 -> let {X,x}=t1' in t2 

Typing                            Г |- t:T

Г |- t2:[X->U]T2
-------------------------------   T-PACK
Г |- {*U,t2} as {$X,T2}:{$X,T2}

Г |- t1:{$X,T12}    Г,X,x:T12 |- t2:T2
--------------------------------------    T-UNPACK
Г |- let {X,x}=t1 in t2:T2


Data Abstraction with Existentials
----------------------------------

The introductory chapter argued that the uses of type systems go far beyond their role in detecting small-scale programming errors like 2+true: they also offer crucial support for programming in the large. In particular, types can be used to enforce not only the abstractions built into the language, but also programmer-defined abstractions - i.e., not only protecting the machine from the program, but protecting parts of the program from each other. This section considers two different styles of abstraction-classical abstract data types, and objects-using existential types as a common frame-work for discussion.

For the sake of fairness, we should note that types are not the only way of protecting programmer-defined abstractions. In untyped languages, similar effects can be achieved using function closures, objects, or special-purpose constructs such as MzScheme's units.

All the examples in this section are purely functional programs. This is purely an expository choice: mechanisms for modularity and abstraction are almost completely orthogonal to the statefulness or statelessness of the abstractions being defined. The reasons for preferring purely functional examples here are that (1) this choice implies that our examples live in a simpler and more economical formal framework, and (2) working with purely functional programs sometimes makes the typing problems more interesting (and their solutions correspondingly more revealing). The reason for this is that, in imperative programming, mutable variables provide a "side-channel" allowing direct communication between distant parts of a program. In purely functional programs, all information that passes between different parts of the program must go via the arguments and results of functions, where it is "visible" to the type system. This is particularly true in the case of objects, and it will force us to postpone treatment of some important features (subtyping and inheritance), where we will have some more powerful type-theoretic machinery at our disposal.


Abstrace Data Types
-------------------

A conventional abstract data type (or ADT) consists of

  (1) a type name A
  (2) a concrete representation type T
  (3) implementations of some operations for creating, querying, and manipulating values of type T
  (4) an abstraction boundary enclosing the representation and operations.

Inside this boundary, elements of the type are viewed concretely (with type T). Outside, they are viewed abstractly, with type A. Values of type A may be passed around, stored in data structures, etc., but not directly examined or changed-the only operations allowed on A are those provided by the ADT.

For example, here is a declaration of an abstract data type of purely functional counters, in a pseudocode notation similar to Ada or Clu:

  ADT counter = type Counter
                representation Nat
                signature
                  new : Counter,
                  get : Counter->Nat,
                  inc : Counter->Counter;
                operations
                  new = 1,
                  get = λi:Nat. i,
                  inc = λi:Nat. succ(i);

  counter.get (counter.inc counter.new);

The abstract type name is Counter; its concrete representation is Nat. The implementations of the operations deal with Counter objects concretely, as Nats: new is just the constant 1; the inc operation is the successor function; get is the identity. The signature section specifies how these operations are to be used externally, replacing some instances of Nat in their concrete types by Counter. The abstraction boundary extends from the ADT keyword to the terminating semicolon; in the remainder of the program (i.e., the last line), the association between Counter and Nat is broken, so that the only thing that can be done with the constant counter.new is to use it as an argument to counter.get or counter.inc.

We can translate this pseudocode almost symbol for symbol into our calculus with existentials. We first create an existential package containing the internals of the ADT:

  counterADT = {*Nat, {new = 1, get = λi:Nat. i, inc = λi:Nat. succ(i)}}
               as {$Counter, {new:Counter, get:Counter->Nat, inc:Counter->Counter}};
  > counterADT : {$Counter, {new:Counter,get:Counter->Nat,inc:Counter->Counter}}

We then open the package, introducing the type variable Counter as a place-holder for the hidden representation type of the package and a term variable counter providing access to the operations:

  let {Counter,counter} = counterADT in counter.get (counter.inc counter.new);
  > 2 : Nat

The version using existential types is slightly harder on the eye, compared to the syntactically sugared pseudocode, but the two are identical in structure.

In general, the body of the let that opens the existential package contains the whole remainder of the program:

  let {Counter,counter} = <counter package> in <rest of program>

In the remainder, the type name Counter can be used just like the base types built into the language. We can define functions that operate on counters, we can even define new abstract data types whose representation involves counters. In this way, a large program can be broken up into a long sequence of ADT declarations, each using the types and operations provided by its predecessors to implement its own, and packaging these up for its successors as a clean, well-defined abstraction.

  let {Counter,counter}=counterADT in
    let add3 = λc:Counter. counter.inc (counter.inc (counter.inc c)) in
      counter.get (add3 counter.new);

A key property of the kind of information hiding we are doing here is representation independence. We can substitute an alternative implementation of the Counter ADT - for example, one where the internal representation is a record containing a Nat rather than just a single Nat, in complete confidence that the whole program will remain typesafe, since we are guaranteed that the rest of the program cannot access instances of Counter except using get and inc.

Experience has shown that a programming style based on abstract data types can yield huge improvements in robustness and maintainability of large systems. There are several reasons for this. First, this style limits the scope of changes to the program. As we saw just above, we can replace one implementation of an ADT by another, possibly changing both its concrete representation type and the implementations of its operations, without affecting the rest of the program, because the typing rules for existential packages ensure that the rest of the program cannot depend on the ADT's internal representation. Second, it encourages programmers to limit the dependencies between the parts of a program by making the signatures of ADTs as small as possible. Finally, and perhaps most importantly, by making the signatures of the operations explicit, it forces programmers to think about designing abstractions.


Existential Objects
-------------------

The "pack and then open" idiom that we saw in the last subsection is the hallmark of ADT-style programming using existential packages. A package defines an abstract type and its associated operations, and we open each package immediately after it is built, binding a type variable for the abstract type and exposing the ADT's operations abstractly. In this section, we show how a simple form of object-style data abstraction can also be viewed as a different programming idiom based on existentials.

We will again use simple counters as our running example, as we did both in the existential ADTs above and in our earlier encounters with objects. We again choose a purely functional style, where sending the message inc to a counter does not change its internal state in-place, but rather returns a fresh counter object with incremented internal state.

A counter object comprises two basic components: a number (its internal state), and a pair of methods, get and inc, that can be used to manipulate the state. We also need to ensure that the only way that the state can be queried or updated is by using one of these two methods. This can be accomplished by wrapping the state and methods in an existential package, abstracting the type of the state. For example, a counter object holding the value 5 might be written

  c = {*Nat, {state = 5, methods = {get = λx:Nat. x, inc = λx:Nat. succ(x)}}} as Counter;

where: Counter = {$X, {state:X, methods: {get:X->Nat, inc:X->X}}};

To use a method of a counter object, we open the existential and apply the appropriate element of its methods to its state field. For example, to get the current value of c we can write:

  let {X,body} = c in body.methods.get(body.state);
  > 5 : Nat

More generally, we can define a little function that "sends the get message" to any counter:

  sendget = λc:Counter. let {X,body} = c in body.methods.get(body.state);
  > sendget : Counter -> Nat

Invoking the inc method of a counter object is a little more complicated. If we simply do the same as for get, the typechecker complains

  let {X,body} = c in body.methods.inc(body.state);
  > Error: Scoping error!

because the type variable X appears free in the type of the body of the let. Indeed, what we've written doesn't make intuitive sense either, since the result of the inc method is a bare internal state, not an object. To satisfy both the typechecker and our informal understanding of what invoking inc should do, we must take this fresh internal state and repackage it as a counter object, using the same record of methods and the same internal state type as in the original object:

  c1 = let {X,body} = c in {*X, {state = body.methods.inc(body.state), methods = body.methods}} as Counter;

More generally, to "send the inc message" to a counter, we can write:

  sendinc = λc:Counter. let {X,body} = c in {*X, {state = body.methods.inc(body.state), methods = body.methods}} as Counter;
  > sendinc : Counter -> Counter

More complex operations on counters can be implemented in terms of these two basic operations:

  add3 = λc:Counter. sendinc (sendinc (sendinc c));
  > add3 : Counter -> Counter


Objects vs ADTs
---------------

The examples in the previous section do not constitute a full-blown model of object-oriented programming. Many of the features including subtyping, classes, inheritance, and recursion via self and super, are missing here. But there are already several interesting comparisons to be made between these simple objects and the ADTs discussed previously.

At the coarsest level, the two programming idioms fall at opposite ends of a spectrum: when programming with ADTs, packages are opened immediately after they are built; on the other hand, when packages are used to model objects they are kept closed as long as possible-until the moment when they must be opened so that one of the methods can be applied to the internal state.

A consequence of this difference is that "the abstract type of counters" refers to different things in the two styles. In an ADT-style program, the counter values manipulated by client code such as the add3 function are elements of the underlying representation type (e.g., simple numbers). In an object-style program, each counter is a whole package-including not only a number, but also the implementations of the get and inc methods. This stylistic difference is reflected in the fact that, in the ADT style, the type Counter is a bound type variable introduced by the let construct, while in the object style Counter stands for the whole existential type {$X, {state:X, methods: {get:X->Nat, inc:X->X}}}.

Thus, at run time, all the counter values generated from the counter ADT are just bare elements of the same internal representation type, and there is a single implementation of the counter operations that works on this internal representation. By contrast, each counter object carries its own representation type together with its own set of methods that work for this representation type.

These differences between objects and ADTs lead to contrasting pragmatic advantages. One obvious one is that, since each object chooses its own representation and carries its own operations, a single program can freely intermix many different implementations of the same object type. This is particularly convenient in the presence of subtyping and inheritance: we can define a single, general class of objects and then produce many different refinements, each with its own slightly (or completely) different representation. Since instances of these refined classes all share the same general type, they can be manipulated by the same generic code, stored together in lists, etc.

For example, a user-interface library may define a generic Window class, with subclasses like TextWindow, ContainerWindow, ScrollableWindow, TitledWindow, DialogBox, etc. Each of these subclasses will include its own particular instance variables (e.g., a TextWindow may use a String instance variable to represent its current contents, whereas a ContainerWindow might use a list of Window objects), and provide specialized implementations of operations like repaint and handleMouseEvent. Defining Window as an ADT, on the other hand, leads to a less flexible structure. The concrete representation type of Window will need to include a variant type with one case for each specific sort of window, carrying the specialized data relevant to that type of window. Operations like repaint will perform a case on the variant and execute the appropriate specialized code. If there are many special forms of windows, this monolithic declaration of the Window ADT can easily grow to be quite large and unwieldy.

A second major pragmatic difference between objects and ADTs concerns the status of binary operations-operations that accept two or more arguments of the same abstract type. To discuss this point coherently, we need to distinguish between two kinds of binary operations:

  * Some binary operations can be implemented entirely in terms of the publicly available operations on two abstract values. For example, to implement an equality operation for counters, all we need to do is ask each for its current value (using get) and compare the two numbers that we get back-i.e., the equal operation can just as well live outside the abstraction boundary that protects the concrete representation of counters. We call such operations weak binary operations.

  * Other binary operations cannot be implemented without concrete, privileged access to the representations of both abstract values. For example, suppose we are implementing an abstraction representing sets of numbers. After scouring several algorithms textbooks, we choose a concrete representation of sets as labeled trees obeying some particular complex invariant. An efficient implementation of the union operation on two sets will need to view both of them concretely, as trees. However, we do not want to expose this concrete representation anywhere in the public interface to our set abstraction. So we will need to arrange for union to have privileged access to both of its arguments that is not available to ordinary client code-i.e., the union operation must live inside the abstraction boundary. We call such operations strong binary operations.

Weak binary operations are an easy case for both of the styles of abstraction we are considering, since it does not make much difference whether we place them inside or outside of the abstraction boundary. If we choose to place them outside, then they may simply be defined as free-standing functions (taking either objects or values of an ADT, as appropriate). Placing them inside an ADT is exactly the same (they will then have concrete access to the representations of their arguments, even though they don't really need it). Placing a weak binary operation inside of an object is only slightly more demanding, since the type of the object now becomes recursive:

  EqCounter = {$X, {state:X, methods: {get:X->Nat, inc:X->X, eq:X->EqCounter->Bool}}}

Strong binary operations, on the other hand, cannot be expressed as methods of objects in our model. We can express their types just as we did for weak binary methods above:

  NatSet = {$X, {state:X, methods: {empty:X, singleton:Nat->X, member:X->Nat->Bool, union:X->NatSet->X}}}

But there is no satisfactory way to implement an object of this type: all we know about the second argument of the union operation is that it provides the operations of NatSet, but these do not give us any way to find out what its elements are so that we can compute the union.

In summary, the single representations of ADTs directly support binary operations, while the multiple representations of objects give up binary methods in return for useful flexibility. These advantages are complementary; neither style dominates the other.

One caveat should be added to this discussion. These comparisons apply to the simple, "purist" model of objects presented earlier in the chapter. The classes in mainstream object-oriented languages like C++ and Java are designed to allow some forms of strong binary methods, and are actually best described as a kind of compromise between the pure objects and pure ADTs that we have seen in this chapter. In these languages, the type of an object is exactly the name of the class from which it was instantiated, and this type is considered distinct from the names of other classes, even if they provide exactly the same operations. That is, a given object type in these languages has a single implementation given by the corresponding class declaration. Moreover, subclasses in these languages can add instance variables only to those inherited from superclasses. These constraints mean that every object belonging to type C is guaranteed to have all the instance variables defined by the (unique) declaration of class C (and possibly some more). It now makes sense for a method of such an object to take another C as an argument and concretely access its instance variables, as long as it uses only instance variables defined by C. This permits strong binary operations such as set union to be defined as methods.


Encoding Existentials
---------------------

The encoding of pairs as a polymorphic type suggests a similar encoding for existential types in terms of universal types, using the intuition that an element of an existential type is a pair of a type and a value:

  {$X,T} =def= "Y.("X.T -> Y) -> Y

That is, an existential package is thought of as a data value that, given a result type and a continuation, calls the continuation to yield a final result. The continuation takes two arguments—a type X and a value of type T—and uses them in computing the final result.

Given this encoding of existential types, the encoding of the packaging and unpackaging constructs is essentially forced. To encode a package

  {*S,t} as {$X,T}

we must use S and t to build a value of type "Y.("X.T -> Y) -> Y. This type begins with a universal quantifier, the body of which is an arrow type. An element of this type should therefore begin with two abstractions:

  {*S,t} as {$X,T} =def= λY.λf:("X.T -> Y). ...

To complete the job, we need to return a result of type Y; clearly, the only way to do this is to apply f to some appropriate arguments. First, we supply the type S (this is a natural choice, being the only type we have lying around at the moment):

  {*S,t} as {$X,T} =def= λY.λf:("X.T -> Y). f[S] ...

Now, the type application f [S] has type [X |-> S](T->Y), i.e., ([X |-> S]T) -> Y. We can thus supply t (which, by rule T-PACK, has type [X |-> S]T) as the next argument:

  {*S,t} as {$X,T} =def= λY.λf:("X.T -> Y). f[S] t

The type of the whole application f [S] t is now Y, as required.

To encode the unpacking construct let {X,x}=t1 in t2, we proceed similarly. First, the typing rule T-UNPACK tells us that t1 should have some type {$X,T11}, that t2 should have type T2 (under an extended context binding X and x:T11), and that T2 is the type we expect for the whole let...in... expression. The intuition here is that the introduction form ({*S,t}) is encoded as an active value that "performs its own elimination." So the encoding of the elimination form here should simply take the existential package t1 and apply it to enough arguments to yield a result of the desired type T2:

  let {X,x} = t1 in t2 =def= t1 ...

The first argument to t1 should be the desired result type of the whole expression, i.e., T2:

  let {X,x} = t1 in t2 =def= t1 [T2] ...

Now, the application t1 [T2] has type ("X. T11->T2) -> T2. That is, if we can now supply another argument of type ("X.T11->T2), we will be finished. Such an argument can be obtained by abstracting the body t2 on the variables X and x:

  let {X,x} = t1 in t2 =def= t1 [T2] (λX.λx:T11.t2)

This finishes the encoding.

Strictly speaking, the fact that the translation requires these extra bits of type information not present in the syntax of terms means that what we are translating is actually typing derivations, not terms. We have seen a similar situation in the definition of the coercion semantics for subtyping before.
