Base Types
----------

Every programming language provides a variety of base types - sets of simple, unstructured values such as numbers, booleans, or characters - plus appropriate primitive operations for manipulating these values.

For theoretical purposes, it is often useful to abstract away from the details of particular base types and their operations, and instead simply suppose that our language comes equipped with some set A of uninterpreted or unknown base types, with no primitive operations on them at all. A can be thought of as standing for atomic types.


The Unit Type
-------------

Unit is a singleton type interpreted in the simplest possible way: we explicitly introduce a single element - the term constant unit (written with a small u) - and a typing rule making unit an element of Unit. We also add unit to the set of possible result values of computations - indeed, unit is the only possible result of evaluating an expression of type Unit.

Even in a purely functional language, the type Unit is not completely without interest, but its main application is in languages with side effects, such as assignments to reference cells. In such languages, it is often the side effect, not the result, of an expression that we care about; Unit is an appropriate result type for such expressions.

This use of Unit is similar to the role of the void type in languages like C and Java. The name void suggests a connection with the empty type Bot, but the usage of void is actually closer to our Unit.

Unit                            extends lambda
----------------------------------------------
t ::= ...                       terms
      unit                      constant unit

v ::= ...                       values
      unit                      constant unit

T ::= ...                       types
      Unit

Г |- unit:Unit                  (T-UNIT)

New derived forms
t1; t2 => (λx:Unit.t2) t1 where x not belongs to FV(t2)

* Jan: If sequence is defined in this form, monad is a natural derivation then

Sequencing is a derived form (theorem)
--------------------------------------

Write λE ("E" for external language) for the simply typed lambda-calculus with the Unit type, the sequencing construct, and the rules E-SEQ, E-SEQNEXT, and T-SEQ, and λI ("I" for internal language) for the simply typed lambda-calculus with Unit only. Let e <- λE -> λI be the elaboration function that translates from the external to the internal language by replacing every occurrence of t1 ; t2 with (λx:Unit.t2) t1, where x is chosen fresh in each case. Now, for each term t of λE, we have

    * t ->E t′ iff e(t) ->I e(t′)
    * Г |-E t:T iff Г |-I e(t):T

where the evaluation and typing relations of λE and λI are annotated with E and I, respectively, to show which is which.

The advantage of introducing features like sequencing as derived forms rather than as full-fledged language constructs is that we can extend the surface syntax (i.e., the language that the programmer actually uses to write programs) without adding any complexity to the internal language about which theorems such as type safety must be proved.

Derived forms are often called syntactic sugar, following Landin. Replacing a derived form with its lower-level definition is called desugaring.

Another derived form that will be useful in examples later on is the "wild-card" convention for variable binders. It often happens (for example, in terms created by desugaring sequencing) that we want to write a "dummy" lambda-abstraction in which the parameter variable is not actually used in the body of the abstraction. In such cases, it is annoying to have to explicitly choose a name for the bound variable; instead, we would like to replace it by a wildcard binder, written _. That is, we will write λ_:S.t to abbreviate λx:S.t, where x is some variable not occurring in t.


Ascription
----------

Ascription is the ability to explicitly ascribe a particular type to a given term (i.e., to record in the text of the program an assertion that this term has this type). We write "t as T" for "the term t, to which we ascribe the type T."

as                              extends lambda
----------------------------------------------
t ::= ...                       terms
      t as T                    ascription

v1 as T -> v1                   E-ASCRIBE

t1 -> t1'
-------------------             E-ASCRIBE1
t1 as T -> t1' as T

Г |- t1:T
--------------                  T-ASCRIBE
Г |- t1 as T:T

There are a number of situations where ascription can be useful in programming. One common one is documentation. It can sometimes become difficult for a reader to keep track of the types of the subexpressions of a large compound expression. Judicious use of ascription can make such programs much easier to follow. Similarly, in a particularly complex expression, it may not even be clear to the writer what the types of all the subexpressions are. Sprinkling in a few ascriptions is a good way of clarifying the programmer's thinking. Indeed, ascription is sometimes a valuable aid in pinpointing the source of puzzling type errors.

Another use of ascription is for controlling the printing of complex types.  A final use of ascription is for abstraction. In systems where a given term t may have many different types (for example, systems with subtyping), ascription can be used to "hide" some of these types by telling the typechecker to treat t as if it had only a smaller set of types. (the relation between ascription and casting will be discussed later)


Let Binding
-----------

it is often useful-both for avoiding repetition and for increasing readability-to give names to some of its subexpressions. 

let                             extends lambda
----------------------------------------------
t ::= ...                       terms
      let x = t1 in t2          let binding

let x = v1 in t2 -> [x->v1]t2   E-LETV

t1 -> t1'
--------------------------------------    E-LET
let x = t1 in t2 ->  let x = t1' in t2

Г |- t1:T1    Г,x:T1 |- t2:T2
-----------------------------   T-LET
Г |- let x = t1 in t2:T2

We can define let binding as derived form too:

let x = t1 in t2 => (λx:T1.t2)t1

But notice that the right-hand side of this abbreviation includes the type annotation T1, which does not appear on the left-hand side. We discover the needed type annotation simply by calculating the type of t1. More formally, what this tells us is that the let constructor is a slightly different sort of derived form than the ones we have seen up till now: we should regard it not as a desugaring transformation on terms, but as a transformation on typing derivations.


Pairs
-----

x                               extends lambda
----------------------------------------------
t ::= ...                       terms
      {t,t}                     pair
      t.1                       first projection
      t.2                       second projection

v ::= ...                       values
      {v,v}                     pair value

T ::= ...                       types
      T1xT2                     product type

{v1,v2}.1 -> v1                 E-PAIRBETA1

{v1,v2}.2 -> v2                 E-PAIRBETA2

t1 -> t1'
-------------                   E-PROJ1
t1.1 -> t1'.1

t1 -> t1'
-------------                   E-PROJ2
t1.2 -> t1'.2

t1 -> t1'
-------------------             E-PAIR1
{t1,t2} -> {t1',t2}

t2 -> t2'
-------------------             E-PAIR2
{v1,t2} -> {v1,t2'}

Г |- t1:T1  Г |- t2:T2
----------------------          T-PAIR
Г |- {t1,t2}:T1xT2

Г |- t1:T11xT12
---------------                 T-PROJ1
Г |- t1.1:T11 

Г |- t1:T11xT12
---------------                 T-PROJ2
Г |- t1.2:T12


Tuples
------

It is easy to generalize the binary products (pairs) to n-ary products, often called tuples. The only cost of this generalization is that, to formalize the system, we need to invent notations for uniformly describing structures of arbitrary arity; such notations are always a bit problematic, as there is some inevitable tension between rigor and readability. We write {ti,i<-1..n} for a tuple of n terms, t1 through tn, and {Ti,i<-1..n} for its type. Note that n here is allowed to be 0; in this case, the range 1..n is empty and {ti,i<-1..n} is {}, the empty tuple. Also, note the difference between a bare value like 5 and a one-element tuple like {5}: the only operation we may legally perform on the latter is projecting its first component.

{}                              extends lambda
----------------------------------------------
t ::= ...                       terms
      {ti,i<-1..n}              tuple
      t.i                       projection

v ::= ...                       values
      {vi,i<-1..n}              tuple value

T ::= ...                       types
      {Ti,i<-1..n}

{vi,i<-1..n}.j -> vj            E-PROJTUPLE

t1 -> t1'
-------------                   E-PROJ
t1.i -> t1'.i

tj -> tj'
---------------------------------------------------------------------    E-TUPLE
{vi,i<-1..j-1, tj, tk,k<-j+1..n} -> {vi,i<-1..j-1, tj', tk,k<-j+1..n}

for each i  Г |- ti:Ti
------------------------------  T-TUPLE
Г |- {ti,i<-1..n}:{Ti,i<-1..n}

Г |- t1:{Ti,i<-1..n}
--------------------            T-PROJ
Г |- t1.j:Tj


Records
-------

{}                              extends lambda
----------------------------------------------
t ::= ...                       terms
      {li=ti,i<-1..n}           record
      t.l                       projection

v ::= ...                       values
      {li=vi,i<-1..n}           record value

T ::= ...                       types
      {li:Ti,i<-1..n}           record type

{li=vi,i<-1..n}.lj -> vj        E-PROJRCD

t1 -> t1'
-------------                   E-PROJ
t1.l -> t1'.l

tj -> tj'
--------------------------------------------------------------------------------------        E-RCD
{li=vi,i<-1..j-1, lj=tj, lk=tk,k<-j+1..n} -> {li=vi,i<1..j-1, lj=tj', lk=tk,k<-j+1..n}

for each i  Г |- ti:Ti
------------------------------------        T-RCD
Г |- {li=ti,i<-1..n}:{li:Ti,i<-1..n}

Г |- t1:{li:Ti,i<-1..n}
-----------------------                     T-PROJ
Г |- t1.lj:Tj

Note that the same "feature symbol," {}, appears in the list of features on the upper-left corner of the definitions of both tuples and products. Indeed, we can obtain tuples as a special case of records, simply by allowing the set of labels to include both alphabetic identifiers and natural numbers. Then when the ith field of a record has the label i, we omit the label. For example, we regard {Bool,Nat,Bool} as an abbreviation for {1:Bool,2:Nat,3:Bool}. (This convention actually allows us to mix named and positional fields, writing {a:Bool,Nat,c:Bool} as an abbreviation for {a:Bool,2:Nat,c:Bool}, though this is probably not very useful in practice.) In fact, many languages keep tuples and records notationally distinct for a more pragmatic reason: they are implemented differently by the compiler.

Programming languages differ in their treatment of the order of record fields. In many languages, the order of fields in both record values and record types has no affect on meaning - i.e., the terms {partno=5524,cost=30.27} and {cost=30.27,partno=5524} have the same meaning and the same type, which may be written either {partno:Nat,cost:Float} or {cost:Float, partno:Nat}. Our presentation chooses the other alternative: {partno=5524,cost=30.27} and {cost=30.27,partno=5524} are different record values, with types {partno:Nat,cost:Float} and {cost:Float, partno:Nat}, respectively.


Sums
----

Many programs need to deal with heterogeneous collections of values. The type-theoretic mechanism that supports this kind of programming is variant types. Before introducing variants in full generality, let us consider the simpler case of binary sum types. A sum type describes a set of values drawn from exactly two given types. Sum is a type whose element is either type A or type B.

We create element of Sum type by tagging its component (with inl and inr, stands for inject left/right). We use case construct/pattern matching to extract its value.

+                               extends lambda
----------------------------------------------
t ::= ...                       terms
      inl t                     tagging (left)
      inr t                     tagging (right)
      case t of inl x => t | inr x => t        case

v ::= ...                       values
      inl v                     tagged value (left)
      inr v                     tagged value (right)

T ::= ...                       types
      T+T                       sum type

case (inl v0)
of inl x1 => t1 | inr x2 => t2  E-CASEINL
  -> [x1->v0]t1

case (inr v0)
of inl x1 => t1 | inr x2 => t2  E-CASEINR
  -> [x2->v0]t2

t0 -> t0'
--------------------------------------------        E-CASE
case t0 of inl x1 => t1 | inr x2 => t2
  -> case t0' of inl x1 => t1 | inr x2 => t2

t1 -> t1'
-----------------               E-INL
inl t1 -> inl t1'

t1 -> t1'
-----------------               E-INR
inr t1 -> inr t1'

Г |- t1:T1
-----------------               T-INL
Г |- inl t1:T1+T2

Г |- t1:T2
-----------------               T-INR
Г |- inr t1:T1+T2

Г |- t0:T1+T2  Г,x1:T1 |- t1:T  Г,x2:T2 |- t2:T
-----------------------------------------------        T-CASE
Г |- case t0 of inl x1 => t1 | inr x2 => t2:T

Most of the properties of the typing relation of pure typed lambda calculus extend to the system with sums, but one important one fails: the Uniqueness of Types theorem. The difficulty arises from the tagging constructs inl and inr. The typing rule T-INL, for example, says that, once we have shown that t1 is an element of T1, we can derive that inl t1 is an element of T1+T2for any type T2. The failure of uniqueness of types means that we cannot build a typechecking algorithm simply by "reading the rules from bottom to top," as we have done for all the features we have seen so far. At this point, we have various options:

  1. We can complicate the typechecking algorithm so that it somehow "guesses" a value for T2. Concretely, we hold T2 indeterminate at this point and try to discover later what its value should have been. Such techniques will be explored in detail when we consider type reconstruction.

  2. We can refine the language of types to allow all possible values for T2 to somehow be represented uniformly. This option will be explored when we discuss subtyping.

  3. We can demand that the programmer provide an explicit annotation to indicate which type T2 is intended. This alternative is the simplest-and it is not actually as impractical as it might at first appear, since, in full-scale language designs, these explicit annotations can often be "piggybacked" on other language constructs and so made essentially invisible (we'll come back to this point in the following section). We take this option for now.

The rules below shows the needed extensions, relative to the rules above. Instead of writing just inl t or inr t, we write inl t as T or inr t as T, where T specifies the whole sum type to which we want the injected element to belong. The typing rules T-INL and T-INR use the declared sum type as the type of the injection, after checking that the injected term really belongs to the appropriate branch of the sum. (To avoid writing T1+T2 repeatedly in the rules, the syntax rules allow any type T to appear as an annotation on an injection. The typing rules ensure that the annotation will always be a sum type, if the injection is well typed.) The syntax for type annotations is meant to suggest the ascription construct from §11.4: in effect these annotations can be viewed as syntactically required ascriptions.

+                               extends lambda
----------------------------------------------
t ::= ...                       types
      inl t as T                tagging (left)
      inr t as T                tagging (right)

v ::= ...                       values
      inl v as T                tagged value (left)
      inr v as T                tagged value (right)

case (inl v0 as T0)
of inl x1 => t1 | inr x2 => t2  E-CASEINL
  -> [x1->v0]t1

case (inr v0 as T0)
of inl x1 => t1 | inr x2 => t2  E-CASEINR
  -> [x2->v0]t2

t1 -> t1'
-----------------------------   E-INL
inl t1 as T2 -> inl t1' as T2

t1 -> t1'
-----------------------------   E-INR
inr t1 as T2 -> inr t1' as T2

Г |- t1:T1
--------------------------      T-INL
Г |- inl t1 as T1+T2:T1+T2

Г |- t1:T2
--------------------------      T-INR
Г |- inr t1 as T1+T2:T1+T2


Variants
--------

Binary sums generalize to labeled variants just as products generalize to labeled records. As with records the order of labels in a variant type is significant here.

<>                              extends lambda
----------------------------------------------
t ::= ...                       terms
      <l=t> as T                tagging
      case t of <li=xi> => ti, i<-1..n        case

T ::= ...                       types
      <li:Ti,i<-1..n>           type of variants

case (<lj=vj> as T) of <li=xi> => ti, i<-1..n
  -> [xj->vj]tj                 E-CASEVARIANT

t0 -> t0'
-------------------------------------------------------------------------        E-CASE
case t0 of <li=xi> => ti, i<-1..n  ->  case t0' of <li=xi> => ti, i<-1..n

ti -> ti'
-----------------------------   E-VARIANT
<li=ti> as T -> <li=ti'> as T

Г |- tj:Tj
-----------------------------------------------        T-VARIANT
Г |- <lj=tj> as <li:Ti,i<-1..n>:<li:Ti,i<-1..n>

Г |- t0:<li:Ti,i<-1..n>    for each i Г,xi:Ti |- ti:T
-----------------------------------------------------        T-CASE
Г |- case t0 of <li=xi> => ti, i<-1..n:T


There are 3 useful "degenerate cases" of variant types: Options, Enumerations and Single Field variants.

Options is either the trivial unit value with the tag none or else a value with the tag 'some'. e.g.

  OptionalNat = <none:Unit, some:Nat>;

OptionalNat is isomorphic to Nat extended with an additional distinguished value none. (familiar? remember Maybe in Haskell?)

Many languages provide built-in support for options. OCaml, for example, predefines a type constructor option, and many functions in typical OCaml programs yield options. Also, the null value in languages like C, C++, and Java is actually an option in disguise. A variable of type T in these languages (where T is a "reference type"—i.e., something allocated in the heap) can actually contain either the special value null or else a pointer to a T value. That is, the type of such a variable is really Ref(Option(T)), where Option(T) = <none:Unit,some:T>. Chapter 13 discusses the Ref constructor in detail.

An enumerated type (or enumeration) is a variant type in which the field type associated with each label is Unit.

  Weekday = <monday:Unit, tuesday:Unit, wednesday:Unit, thursday:Unit, friday:Unit>;

The concrete syntax we are using here is not well tuned for making such programs easy to write or read. some languages (beginning with Pascal) provide special syntax for declaring and using enumerations. Others—such as ML, cf. page 141—make enumerations a special case of the variants.

Single-Field variants is variant types with just a single label l:

  V = <l:T>

Such a type might not seem very useful at first glance: after all, the elements of V will be in one-to-one correspondence with the elements of the field type T, since every member of V has precisely the form <l=t> for some t : T. What's important, though, is that the usual operations on T cannot be applied to elements of V without first unpackaging them: a V cannot be accidentally mistaken for a T. e.g.

  DollarAmount = <dollars:Float>;
  EuroAmount = <euros:Float>;


Variants vs Datatypes
---------------------

A variant type T of the form <li:Ti,i<-1..n> is roughly analogous to the ML datatype defined by:

  type T = l1 of T1
         | l2 of T2
         | ...
         | ln of Tn

But there are several differences worth noticing.

   1. One trivial but potentially confusing point is that the capitalization conventions for identifiers that we are assuming here are different from those of OCaml. In OCaml, types must begin with lowercase letters and datatype constructors (labels, in our terminology) with capital letters, so, strictly speaking, the datatype declaration above should be written like this:

        type t = L1 of t1 | ... | Ln of tn

      To avoid confusion between terms t and types T, we'll ignore OCaml's conventions for the rest of this discussion and use ours instead.

   2. The most interesting difference is that OCaml does not require a type annotation when a constructor li is used to inject an element of Ti into the datatype T: we simply write li(t). The way OCaml gets away with this (and retains unique typing) is that the datatype T must be declared before it can be used. Moreover, the labels in T cannot be used by any other datatype declared in the same scope. So, when the typechecker sees li(t), it knows that the annotation can only be T. In effect, the annotation is "hidden" in the label itself. This trick eliminates a lot of silly annotations, but it does lead to a certain amount of grumbling among users, since it means that labels cannot be shared between different datatypes—at least, not within the same module. Latter we will see another way of omitting annotations that avoids this drawback.

   3. Another convenient trick used by OCaml is that, when the type associated with a label in a datatype definition is just Unit, it can be omitted altogether. This permits enumerations to be defined by writing

        type Weekday = monday | tuesday | wednesday | thursday | friday

      Similarly, the label monday all by itself (rather than monday applied to the trivial value unit) is considered to be a value of type Weekday.

   4. Finally, OCaml datatypes actually bundle variant types together with several additional features that we will be examining, individually, in later chapters.

      * A datatype definition may be recursive—i.e., the type being defined is allowed to appear in the body of the definition. For example, in the standard definition of lists of Nats, the value tagged with cons is a pair whose second element is a NatList.

          type NatList = nil
                       | cons of Nat * NatList

      * An OCaml datatype can be [parametric data type]parameterizedparametric!data type on a type variable, as in the general definition of the List datatype:

          type 'a List = nil
                       | cons of 'a * 'a List

        Type-theoretically, List can be viewed as a kind of function—called a type operator—that maps each choice of ′a to a concrete datatype... Nat to NatList, etc.


Variants as Disjoint Unions
---------------------------

Sum and variant types are sometimes called disjoint unions. The type T1+T2 is a "union" of T1 and T2 in the sense that its elements include all the elements from T1 and T2. This union is disjoint because the sets of elements of T1 or T2 are tagged with inl or inr, respectively, before they are combined, so that it is always clear whether a given element of the union comes from T1 or T2. The phrase union type is also used to refer to untagged (non-disjoint) union types.


Type Dynamic
------------

Even in statically typed languages, there is often the need to deal with data whose type cannot be determined at compile time. This occurs in particular when the lifetime of the data spans multiple machines or many runs of the compiler—when, for example, the data is stored in an external file system or database, or communicated across a network. To handle such situations safely, many languages offer facilities for inspecting the types of values at run time.

One attractive way of accomplishing this is to add a type Dynamic whose values are pairs of a value v and a type tag T where v has type T. Instances of Dynamic are built with an explicit tagging construct and inspected with a type safe typecase construct. In effect, Dynamic can be thought of as an infinite disjoint union, whose labels are types.


General Recursion
-----------------

We have seen in the untyped lambda-calculus recursive functions can be defined with the aid of the fix combinator. They can be defined in a typed setting in a similar way. For example, here is a function iseven that returns true when called with an even argument and false otherwise:

  ff = λie:Nat -> Bool.
       λx:Nat.
         if iszero x then true
         else if iszero (pred x) then false
         else ie (pred (pred x));
  > ff : (Nat -> Bool) -> Nat -> Bool

  iseven = fix ff;
  > iseven : Nat -> Bool

  iseven 7;
  > false : Bool

The intuition is that the higher-order function ff passed to fix is a generator for the iseven function: if ff is applied to a function ie that approximates the desired behavior of iseven up to some number n (that is, a function that returns correct results on inputs less than or equal to n), then it returns a better approximation to iseven—a function that returns correct results for inputs up to n + 2. Applying fix to this generator returns its fixed point — a function that gives the desired behavior for all inputs n.

However, there is one important difference from the untyped setting: fix itself cannot be defined in the simply typed lambda-calculus. Indeed, we will see later that no expression that can lead to non-terminating computations can be typed using only simple types. So, instead of defining fix as a term in the language, we simply add it as a new primitive, with evaluation rules mimicking the behavior of the untyped fix combinator and a typing rule that captures its intended uses.


fix                             extends lambda
----------------------------------------------
t ::= ...                       terms
      fix t                     fixed point of t

fix(λx:T1.t2)                   E-FIXBETA
  -> [x->(fix(λx.T1.t2))]t2

t1 -> t1'
-----------------               E-FIX
fix t1 -> fix t1'

Г |- t1:T1 -> T1
----------------                T-FIX
Г |- fix t1:T1

letrec x:T1 = t1 in t2          new derived form
  def= let x = fix (λx:T1.t1) in t2

The simply typed lambda-calculus with numbers and fix has long been a favorite experimental subject for programming language researchers, since it is the simplest language in which a range of subtle semantic phenomena such as full abstraction (Plotkin, 1977, Hyland and Ong, 2000, Abramsky, Jagadeesan, and Malacaria, 2000) arise. It is often called PCF.

The fix construct is typically used to build functions (as fixed points of functions from functions to functions), but it is worth noticing that the type T in rule T-FIX is not restricted to function types. This extra power is some-times handy. For example, it allows us to define a record of mutually recursive functions as the fixed point of a function on records (of functions). The following implementation of iseven uses an auxiliary function isodd; the two functions are defined as fields of a record, where the definition of this record is abstracted on a record ieio whose components are used to make recursive calls from the bodies of the iseven and isodd fields.

  ff = λieio:{iseven:Nat->Bool, isodd:Nat->Bool}.
         {iseven = λx:Nat.
                   if iszero x then true
                   else ieio.isodd (pred x),
          isodd = λx:Nat.
                   if iszero x then false
                   else ieio.iseven (pred x)};
  > ff : {iseven:Nat->Bool,isodd:Nat->Bool} -> {iseven:Nat->Bool, isodd:Nat->Bool}

Forming the fixed point of the function ff gives us a record of two functions

  r = fix ff;
  > r : {iseven:Nat->Bool, isodd:Nat->Bool}

and projecting the first of these gives us the iseven function itself:

  iseven = r.iseven;
  > iseven : Nat -> Bool

The ability to form the fixed point of a function of type T->T for any T has some surprising consequences. In particular, it implies that every type is inhabited by some term. To see this, observe that, for every type T, we can define a function divergeT as follows:

  divergeT = λ_:Unit. fix (λx:T.x);
  > divergeT : Unit -> T

Whenever divergeT is applied to a unit argument, we get a non-terminating evaluation sequence in which E-FIXBETA is applied over and over, always yielding the same term. That is, for every type T, the term divergeT unit is an undefined element of T.

One final refinement that we may consider is introducing more convenient concrete syntax for the common case where what we want to do is to bind a variable to the result of a recursive definition. In most high-level languages, the first definition of iseven above would be written something like this:

  letrec iseven : Nat->Bool =
         λx:Nat.
          if iszero x then true
          else if iszero (pred x) then false
          else iseven (pred (pred x))
  in iseven 7;
  > false : Bool

The recursive binding construct letrec is easily defined as a derived form:

  letrec x:T1 = t1 in t2    def=    let x = fix (λx:T1.t1) in t2


Lists
-----

The typing features we have seen can be classified into base types like Bool and Unit, and type constructors like → and × that build new types from old ones. Another useful type constructor is List. For every type T, the type List T describes finite-length lists whose elements are drawn from T.

List                            extends lambda
----------------------------------------------
t ::= ...                       terms
      nil[T]                    empty list
      cons[T] t t               list constructor
      isnil[T] t                test for empty list
      head[T] t                 head of a list
      tail[T] t                 tail of a list

v ::= ...                       values
      nil[T]                    empty list
      cons[T] v v               list constructor

T ::= ...                       types
      List T                    type of list

t1 -> t1'
------------------------------- E-CONS1
cons[T] t1 t2 -> cons[T] t1' t2

t2 -> t2'
------------------------------- E-CONS2
cons[T] v1 t2 -> cons[T] v1 t2'

isnil[S](nil[T]) -> true        E-ISNILNIL

isnil[S](cons[T] v1 v2) -> false        E-ISNILCONS

t1 -> t1'
---------------------------     E-ISNIL
isnil[T] t1 -> isnil[T] t1'

head[S](cons[T] v1 v2) -> v1    E-HEADCONS

t1 -> t1'
-------------------------       E-HEAD
head[T] t1 -> head[T] t1'

tail[S](cons[T] v1 v2) -> v2    E-TAILCONS

t1 -> t1'
-------------------------       E-TAIL
tail[T] t1 -> tail[T] t1'

Г |- nil[T1]:List T1            T-NIL

Г |- t1:T1    Г |- t2:List T1
-----------------------------   T-CONS
Г |- cons[T1] t1 t2:List T1

Г |- t1:List T11
----------------------          T-ISNIL
Г |- isnil[T11]t1:Bool

Г |- t1:List T11
--------------------            T-HEAD
Г |- head[T11]t1:T11

Г |- t1:List T11
-------------------------       T-TAIL
Г |- tail[T11]t1:List T11

We adopt the "head/tail/isnil presentation" of lists here for simplicity. from the perspective of language design, it is arguably better to treat lists as a datatype and use case expressions for destructing them, since more programming errors can be caught as type errors this way.


Shared State
------------

The possibility of aliasing can make programs with references quite tricky to reason about. For example, the expression (r:=1; r:=!s), which assigns 1 to r and then immediately overwrites it with s's current value, has exactly the same effect as the single assignment r:=!s, unless we write it in a context where r and s are aliases for the same cell.

Of course, aliasing is also a large part of what makes references useful. In particular, it allows us to set up "implicit communication channels"-shared state-between different parts of a program. Based on this we can construct simple object.


References to Compound Types
----------------------------

A reference cell need not contain just a number: the primitives above allow us to create references to values of any type, including functions. For example, we can use references to functions to give a (not very efficient) implementation of arrays of numbers, as follows. Write NatArray for the type Ref (Nat->Nat).

  NatArray = Ref (Nat->Nat);

To build a new array, we allocate a reference cell and fill it with a function that, when given an index, always returns 0.

  newarray = λ_:Unit. ref (λn:Nat.0);
  > newarray : Unit -> NatArray

To look up an element of an array, we simply apply the function to the desired index.

  lookup = λa:NatArray. λn:Nat. (!a) n;
  > lookup : NatArray -> Nat -> Nat

The interesting part of the encoding is the update function. It takes an array, an index, and a new value to be stored at that index, and does its job by creating (and storing in the reference) a new function that, when it is asked for the value at this very index, returns the new value that was given to update, and on all other indices passes the lookup to the function that was previously stored in the reference.

  update = λa:NatArray. λm:Nat. λv:Nat.
           let oldf = !a in
           a := (λn:Nat. if equal m n then v else oldf n);
  > update : NatArray -> Nat -> Nat -> Unit


Garbage Collection
------------------

A last issue that we should mention before we move on formalizing references is storage deallocation. We have not provided any primitives for freeing reference cells when they are no longer needed. Instead, like many modern languages (including ML and Java) we rely on the run-time system to perform garbage collection, collecting and reusing cells that can no longer be reachedby the program. This is not just a question of taste in language design: it is extremely difficult to achieve type safety in the presence of an explicit deallocation operation. The reason for this is the familiar dangling reference problem: we allocate a cell holding a number, save a reference to it in some data structure, use it for a while, then deallocate it and allocate a new cell holding a boolean, possibly reusing the same storage. Now we can have two names for the same storage cell-one with type Ref Nat and the other with type Ref Bool.
